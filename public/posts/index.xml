<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Electronic Lab Notebook</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Electronic Lab Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>eunise.aquino@connect.qut.edu.au (Martha Aquino)</managingEditor>
    <webMaster>eunise.aquino@connect.qut.edu.au (Martha Aquino)</webMaster>
    <copyright>(c) 2018 -- All rights reserved.</copyright>
    <lastBuildDate>Fri, 21 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>GWAS rerun MAF 0.05</title>
      <link>/posts/gwas-rerun-maf-0-05/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/gwas-rerun-maf-0-05/</guid>
      <description>require(magicfor)## Loading required package: magicfor## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,## logical.return = TRUE, : there is no package called &amp;#39;magicfor&amp;#39;require(magrittr)## Loading required package: magrittrrequire(dplyr)## Loading required package: dplyr## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionrequire(gaston)## Loading required package: gaston## Loading required package: Rcpp## Loading required package: RcppParallel## ## Attaching package: &amp;#39;RcppParallel&amp;#39;## The following object is masked from &amp;#39;package:Rcpp&amp;#39;:## ## LdFlags## Gaston set number of threads to 2.</description>
    </item>
    
    <item>
      <title>Using variants unfiltered for MAF for PCA and heritability analysis</title>
      <link>/posts/using-variants-unfiltered-for-maf-for-pca-and-heritability-analysis/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/using-variants-unfiltered-for-maf-for-pca-and-heritability-analysis/</guid>
      <description>IntroductionMethods and Results1. Run PCA with 20 PCs on unfiltered MAF data setplink1.9 --bfile merged_nies/merged_nies_geno_210818 --pca 20 var-wts --out plink_output/nies_geno_pca261118Note:
the merged_nies_geno_210818 contains the data set after HWE and missingness filters (contains 3.9 million variants).
20 PCs included. From the previous entry, it seemed that including 20PCs produced consistently higher heritability estimates than including 1 - 5 PC.
2. Generate PCA plotsLoad .</description>
    </item>
    
    <item>
      <title>Re-estimating heritability of traits - GCTA </title>
      <link>/posts/re-estimating-heritability-of-traits-gcta/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/re-estimating-heritability-of-traits-gcta/</guid>
      <description>IntroductionTo determine whether the low frequency variants were affecting the heritability estimates, heritabiity analysis must be re-performed with the new genomic data set.
Since ‘gaston’ is still unable to produce p-values for the heritability estimates, GCTA will be used to perform the analysis.
Methods and Results1. Generate a GRM./gcta64 --bfile merged_nies/merged_nies_geno071118 --make-grm --out gcta_output/merged_nies_grm0911182. Perform PCA for inclusion as covariates./gcta64 --grm gcta_output/merged_nies_grm091118 --pca 20 --out gcta_output/merged_nies_pca091118This step performs a PCA on the genomic data, like in PLINK, however it only generates results for 2 principal components.</description>
    </item>
    
    <item>
      <title>Excluding low frequency variants and genomic PCA</title>
      <link>/posts/excluding-low-frequency-variants-and-genomic-pca/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/excluding-low-frequency-variants-and-genomic-pca/</guid>
      <description>IntroductionDespite including age, sex, and population structure as covariates in the heritability and GWAS models, the results still seemed to be inflated. This was indicated by the many variants passing genome-wide significance, particularly for Component 1, 3, and R Cyl. Prior to adding the covariates, the QQ plots also displayed shelving, indicating that there were more variants passing the threshold than expected. Although, this alone could be normal and indicative of many variants in LD, in conjunction with the messy peaks on the manhattan plot, the results seem suspicious.</description>
    </item>
    
    <item>
      <title>Generating beta-values for significant SNPs</title>
      <link>/posts/generating-beta-values-for-significant-snps/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/generating-beta-values-for-significant-snps/</guid>
      <description>IntroductionThe heritability values obtained from the previous GWAS using lmm and lrt appear to be artificially inflated. Therefore, beta values may be a better indication of SNP effect, which can be obtained by using the wald test, instead of lrt.
Methods and ResultsLoad packagesrequire(magicfor)require(magrittr)require(dplyr)require(gaston)require(qqman)Load datanies_heritable_pheno240918 &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/nies_heritable_pheno240918.csv&amp;#39;, header = TRUE)nies_covar &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/nies_covar.csv&amp;#39;, header = T)head(nies_covar)## UUID Sex Age## 1 219960 1 53## 2 313180 1 55## 3 320511 2 60## 4 400011 1 23## 5 400013 1 50## 6 316131 2 77merged_nies_210818 &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Filtering GWAS (w/ covariates) results </title>
      <link>/posts/filtering-gwas-w-covariates-results/</link>
      <pubDate>Tue, 25 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/filtering-gwas-w-covariates-results/</guid>
      <description>IntroductionThe addition of covariates to the heritability and GWAS models significantly changed my results. As such, I need to filter for robust peaks in my new GWAS results and obtaining beta-values for the signiicant peaks.
Methods and ResultsLoad packagesrequire(magicfor)## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,## logical.return = TRUE, : there is no package called &amp;#39;magicfor&amp;#39;require(magrittr)require(dplyr)require(gaston)require(qqman)Load datanies_heritable_pheno240918 &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Adding age and sex as covariates </title>
      <link>/posts/adding-age-and-sex-as-covariates/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/adding-age-and-sex-as-covariates/</guid>
      <description>require(magicfor)## Loading required package: magicforrequire(magrittr)## Loading required package: magrittrrequire(dplyr)## Loading required package: dplyr## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionrequire(gaston)## Loading required package: gaston## Loading required package: Rcpp## Loading required package: RcppParallel## ## Attaching package: &amp;#39;RcppParallel&amp;#39;## The following object is masked from &amp;#39;package:Rcpp&amp;#39;:## ## LdFlags## Gaston set number of threads to 2.</description>
    </item>
    
    <item>
      <title>SNP heritability</title>
      <link>/posts/snp-heritability/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/snp-heritability/</guid>
      <description>IntroductionSNP heritability of index SNPs are non-sense. The numbers I am obtaining are either too high or too low. Therefore, I want to compare GWAS results using the lmm/LRT method vs lm/Wald method. The wald test will also generate beta-values which are alternative values that indicate the effect size of SNVs.
Methods and Resultsrequire(magrittr)require(dplyr)require(gaston)require(qqman)Load relevant datanies_heritable_pheno &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/nies_heritable_pheno.csv&amp;#39;, header = T)merged_nies_210818 &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Annotating signficant GWAS hits</title>
      <link>/posts/annotating-signficant-gwas-hits/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/annotating-signficant-gwas-hits/</guid>
      <description>IntroductionThe pedigree-based GWAS identified 9 heritable traits with significant hits (i.e. SNPs that pass genome-wide significance threshold, p &amp;lt; 1.84e-7). The number of significant hits within each trait highly varied. To identify the most robust hits, SNPs that pass the genome-wide signficance threshold would ideally have adjacent SNPs that pass the suggestive threshold. Therefore, I will attempt to filter the significant hits/loci based on the presence of significant (suggestive) SNPs.</description>
    </item>
    
    <item>
      <title>Performing GWAS on heritable traits</title>
      <link>/posts/performing-gwas-on-heritable-traits/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/performing-gwas-on-heritable-traits/</guid>
      <description>require(magrittr)## Loading required package: magrittrrequire(dplyr)## Loading required package: dplyr## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionrequire(gaston)## Loading required package: gaston## Loading required package: Rcpp## Loading required package: RcppParallel## ## Attaching package: &amp;#39;RcppParallel&amp;#39;## The following object is masked from &amp;#39;package:Rcpp&amp;#39;:## ## LdFlags## Gaston set number of threads to 2.</description>
    </item>
    
    <item>
      <title>MLMA GWAS for most heritable trait</title>
      <link>/posts/mlma-gwas-for-most-heritable-trait/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/mlma-gwas-for-most-heritable-trait/</guid>
      <description>IntroductionAfter obtaining heritability estimates for all traits and principal components, I can prioritise the traits for GWAS. There are different methods for performing GWAS and analysing GWAS results in GCTA. In particular, I am interested in the MLMA method which is mixed linear model associations (https://www.ncbi.nlm.nih.gov/pubmed/24473328).
Methods and Results1. Run GWAS-MLMA on R K-value V./gcta64 --mlma --bfile merged_nies/merged_nies_geno_210818 --grm gcta_output/merged_nies_grm --pheno nies_pheno_020918.txt --mpheno 11 --out gcta_output/r_kval_mlmar_kvalV_mlma &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Estimating heritability of principal components using GCTA</title>
      <link>/posts/estimating-heritability-of-principal-components-using-gcta/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/estimating-heritability-of-principal-components-using-gcta/</guid>
      <description>IntroductionAfter trying GCTA for estimating the heritability of individual traits and comparing its results with results obtained from gaston, the heritability of the phenotypic PCs need to be estimated as well.
Methods and Results1. Prepare principal component resultsGCTA requires the phenotypic input file to be a plain text file and have the family and UUID in the first two columns and it does not recognise headers. I converted the csv file to text file, removed the headers, and added a family ID column.</description>
    </item>
    
    <item>
      <title>Trying GCTA to perform heritability analysis</title>
      <link>/posts/trying-gcta-to-perform-heritability-analysis/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/trying-gcta-to-perform-heritability-analysis/</guid>
      <description>IntroductionAlthough heritability estimates have been obtained from gaston, I was unable to obtain signficance values for the estimates. This is important as it will help me prioritise the phenotypes and principal components that will be carried forward to the pedigree-based GWAS. Therefore, I will attempt to re-calculate the heritability estimates using GCTA (http://cnsgenomics.com/software/gcta/#Overview). GCTA is a command line program that uses PLINK input and output.
Methods and Results1.</description>
    </item>
    
    <item>
      <title>Including principal components for estimating heritability</title>
      <link>/posts/including-principal-components-for-estimating-heritability/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/including-principal-components-for-estimating-heritability/</guid>
      <description>IntroductionRecent studies suggest that hidden population stratification can singificantly inflate heritability estimates. It is therefore imperative that population structure is accounted for when estimating heritability by including principal components in the linear mixed model. Typically, 10 to 20 principal components are used for this correction in outbred populations, but these numbers have no theoretical basis. A paper by Dandine-Roulland et al. (2016) has shown that heritability estimates are significantly affected with the inclusion of the first principal component, but not of any more (https://www.</description>
    </item>
    
    <item>
      <title>Using gaston for estimating heritability-1</title>
      <link>/posts/using-gaston-for-estimating-heritability-1/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/using-gaston-for-estimating-heritability-1/</guid>
      <description>IntroductionThe genetic relationship matrix generated from the previous exercise contains values that signify the degree of relatedness between the individuals. This will allow me to estimate the heritability of the traits and principal components identified in the first objective.
To recap this concept, traits can vary among individuals due to environmental and genetic factors. Estimating the heritability of a trait means determining the proportion of variance that can be attributed to genetics (https://www.</description>
    </item>
    
    <item>
      <title>Trying gaston to generate genetic relationship matrix</title>
      <link>/posts/trying-gaston-to-generate-genetic-relationship-matrix/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/trying-gaston-to-generate-genetic-relationship-matrix/</guid>
      <description>require(gaston)IntroductionGaston is an R package that allows for manipulation and analysis of SNP data. For this project, it will be used to estimate heritability of the phenotypes and perform the pedigree-based linear mixed model GWAS (https://cran.r-project.org/web/packages/gaston/vignettes/gaston.pdf).
Methods and Results1. Re-filter the SNP data.In the previous entry, I manually subsetted data for individuals before merging the data sets such that PLINK does not have to handle duplicate samples.</description>
    </item>
    
    <item>
      <title>Performing PCA on filtered NIES genomic data</title>
      <link>/posts/performing-pca-on-filtered-nies-genomic-data/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/performing-pca-on-filtered-nies-genomic-data/</guid>
      <description>IntroductionAfter addressing the missing genotype filtering issue, the PCA on the final data set will need to be repeated. Performing a PCA will reveal population structure and will reveal any underlying genetic structures in the genomic data.
Methods and ResultsNote: I forgot to change the paternal and maternal IDs before I re-did the merge and it seemed to be causing issues with the PCA. I changed the paternal and maternal IDs in the final data set (nies_miss_filtered) ONLY.</description>
    </item>
    
    <item>
      <title>Re-trying default merge</title>
      <link>/posts/re-trying-default-merge/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/re-trying-default-merge/</guid>
      <description>IntroductionThe missing genotype filtering is still removing more variants than expected. We suspect that PLINK may not be handling the overlapping data/duplicate samples well. Therefore, I will be removing the SNP-array data for individuals that have duplicate data before attempting to merge the data set using the default setting (consensus calls) in PLINK.
Methods and Results1. Identify individuals with SNP-array only and duplicate data.Using the master spreadsheet containing UUIDs, I 1) isolated all NIES individuals, 2) isolated NIES individuals with SNP data (GWAS_NIES), 3) separate individuals with potential duplicates and SNP-array data.</description>
    </item>
    
    <item>
      <title>Troubleshooting missing genotype filtering</title>
      <link>/posts/troubleshooting-missing-genotype-filtering/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/troubleshooting-missing-genotype-filtering/</guid>
      <description>IntroductionApplying a missing genotype filter for individuals and markers (described in previous entry) yielded unexpected results as a significant number of individuals and variants were removed. Considering the high genotyping rates (~99%) of the original files (WGS and SNP-array), there should only be a small number of variants removed due to missing genotypes.
This exercise is aimed at determining the possible cause for this filtering issue by testing the filtering parameters on the original data set and merged data set.</description>
    </item>
    
    <item>
      <title>Performing PCA on genomic data</title>
      <link>/posts/performing-pca-on-genomic-data/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/performing-pca-on-genomic-data/</guid>
      <description>IntroductionThe final step to the second part of aim 1 is to perform a PCA on the genomic data to investigate the population structure. This is important because it will allow me to determine if there are any underlying genetic structures in the genomic data and I can account for relatedness among individuals for subsequent analyses.
Methods and Results1. Run PCAplink1.9 --bfile merged_nies --pca 180 var-wts --out plink_output/nies_final_pcaThe count had to be increased (default is 20) because there are over 100 components with an eigenvalue &amp;gt;1.</description>
    </item>
    
    <item>
      <title>Generating stats for merged data and extracting data for NIES</title>
      <link>/posts/generating-stats-for-merged-data-and-extracting-data-for-nies/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/generating-stats-for-merged-data-and-extracting-data-for-nies/</guid>
      <description>IntroductionNow that the merge has been successful and there should no longer be duplicated individuals, general stats need to be performed on the merged data set. Subsequently, the final step to this data prep and cleaning is to extract data for the NIES individuals only.
Methods and ResultsNote: Most processes up until the merge from the previous entry was performed on taurus. I transferred filtered_merge to local directory. These stat tests will be performed locally.</description>
    </item>
    
    <item>
      <title>Fixing WGS ID and merging data</title>
      <link>/posts/fixing-wgs-id-and-merging-data/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/fixing-wgs-id-and-merging-data/</guid>
      <description>IntroductionPrior to merging the data sets, I need to fix the IDs in the WGS data as they are not UUIDs and are therefore recognising all individuals as unique despite having an overlap.
Methods and Results1. Load WGS fam filewgs_fam_data &amp;lt;- read.table(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/plink_output/wgs_filtered.fam&amp;#39;, header = F)head(wgs_fam_data)## V1 V2 V3 V4 V5 V6## 1 1 110390 0 0 2 -9## 2 1 110990 0 0 1 -9## 3 1 111280 0 0 2 -9## 4 1 111800 0 0 2 -9## 5 1 111830 0 0 2 -9## 6 1 124520 0 0 1 -92.</description>
    </item>
    
    <item>
      <title>Extracting data for variants common in both file sets </title>
      <link>/posts/extracting-data-for-variants-common-in-both-file-sets/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/extracting-data-for-variants-common-in-both-file-sets/</guid>
      <description>IntroductionThe merge function in PLINK appears to exclude variants that are common in both data sets, which is unexpected.The following work around extracts the variants common in both file sets and merges the data.
NOTE: this exercise was performed on taurus.
Methods and Results1. Extract SNP IDs from both .bim files and sort them numerically.awk &amp;#39;{print $2}&amp;#39; NI.snp.hg38_final.bim | sort &amp;gt; array_snp_hg38_sorted.txtawk &amp;#39;{print $2}&amp;#39; NI_wgs_merged_snps.bim | sort &amp;gt; wgs_snp_hg38_sorted.</description>
    </item>
    
    <item>
      <title>Generating basic statistics for final genomic data sets</title>
      <link>/posts/generating-basic-statistics-for-final-genomic-data-sets/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/generating-basic-statistics-for-final-genomic-data-sets/</guid>
      <description>IntroductionAfter obtaining the unfiltered WGS data and converting the SNP-array data to a hg38 genome reference build, I can generate basic stats, QC, and merge. There should not be anymore changes to the base data sets moving forward.
Methods and Results1.Find allele frequencies in both file setsplink1.9 --bfile NI.snp.hg38_final --freq --out plink_output/snp_allele_freqOutput: - 26,055,300 variants loaded - 506 individuals (247 males, 259 females) - 45 founders - genotyping rate is 98.</description>
    </item>
    
    <item>
      <title>Converting SNP array data </title>
      <link>/posts/converting-snp-array-data/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/converting-snp-array-data/</guid>
      <description>IntroductionThe SNP array was imputed using hg19 coordinates which is conflicting with the hg38 build (used for WGS). Therefore, the array data has to be converted to hg38 before re-running all summary statistics and further analyses.
Methods1.Access taurus through WinSCP2.Transfer files from local directory to remote directory/data/all/martha
3.Convert bed files to ped filesplink --bfile NImerged.impute2.chrAllX.2014-Oct-02 --recode --tab --out plink_output/NImerged.impute2.chrAllXThis has converted the .</description>
    </item>
    
    <item>
      <title>Merging genomic data sets</title>
      <link>/posts/merging-genomic-data-sets/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/merging-genomic-data-sets/</guid>
      <description>IntroductionMerging the two genomic data sets caused an error because my laptop has inadequate RAM to perform the merge in a single command. Therefore, I will split the data and merge them by chromosome and stitch these together to create a unified merged file set.
Method1. Use ‘for’ loop to split SNP data by chromosomefor i in {1..23}do plink1.9 --bfile plink_output/snp_exclude --chr $i --make-bed --out merged_chr_data/snp_chr$idone2.</description>
    </item>
    
    <item>
      <title>Cleaning and preparing genomic data </title>
      <link>/posts/cleaning-and-preparing-genomic-data/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/cleaning-and-preparing-genomic-data/</guid>
      <description>IntroductionAfter performing basic stats and QC on the genomic data sets, merging, and subsetting the data for NIES individuals, a few issues came to my attention. Firstly, from the histograms of the distribution of allele frequencies from the whole genome sequencing data, it became evident that the data had been filtered to exlude SNPs with MAF &amp;lt; 0.05. Thus any rare variants that I need for GWAS was excluded. Second, the IDs in the whole genome sequencing data were not UUIDs.</description>
    </item>
    
    <item>
      <title>Extracting genomic data exclusive to NIES</title>
      <link>/posts/extracting-genomic-data-exclusive-to-nies/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/extracting-genomic-data-exclusive-to-nies/</guid>
      <description>IntroductionAfter extracting data for the common variants, the last cleaning step is to extract genomic data for NIES individuals only. Unique identifiers are used for individuals and a unique list of UUIDs need to be identified to extract the relevant data.
Methods and ResultsLoad .fam file from the merged data set. (.fam file contains UUIDs of individuals with genomic data)merged_fam_data &amp;lt;- read.table(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/plink_output/common_id_merge.fam&amp;#39;, header = F)head(merged_fam_data)## V1 V2 V3 V4 V5 V6## 1 1 110050 764 368910 1 -9## 2 1 110110 2621 400796 1 -9## 3 1 110130 2994 2330 1 -9## 4 1 110150 0 0 2 -9## 5 1 110160 2070 2071 1 -9## 6 1 110320 4462 6317 1 -92.</description>
    </item>
    
    <item>
      <title>Generating basic statistics for merged data set</title>
      <link>/posts/generating-basic-statistics-for-merged-data-set/</link>
      <pubDate>Wed, 04 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/generating-basic-statistics-for-merged-data-set/</guid>
      <description>IntroductionError when extracting common variant IDs needs to be resolved.
After successfully exporting the list of common IDs, the relevant genomic data will need to be extracted and basic statistics will need to be generated.
Methods and resultsI believe the error in PLINK when extracting data is due to the formatting of the IDs in the text file.
1.Try removing quotation marks from the list of IDs</description>
    </item>
    
    <item>
      <title>Extracting common variants from both data sets</title>
      <link>/posts/extracting-common-variants-from-both-data-sets/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/extracting-common-variants-from-both-data-sets/</guid>
      <description>IntroductionThe merged data set did not produce the expected output. I expected that the merging would only retain data from common variants between both genomic data sets. To resolve this, I need to compare the two data sets and extract the list of common variant IDs and use this to extract the relevant data.
Methods1.Load .bim files for both data sets
wgs_bim_data &amp;lt;- read.table(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/NI_wgs_merged_snps.bim&amp;#39;, header = F)head(wgs_bim_data)## V1 V2 V3 V4 V5 V6## 1 1 1:11075 0 11075 A G## 2 1 rs546169444 0 14464 T A## 3 1 rs2691315 0 15820 T G## 4 1 rs375964566 0 15922 G A## 5 1 rs112448831 0 15956 A G## 6 1 rs372319358 0 16068 C Tsnp_bim_data &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Generating basic statistics for genomic data sets</title>
      <link>/posts/generating-basic-statistics-for-genomic-data-sets/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/generating-basic-statistics-for-genomic-data-sets/</guid>
      <description>IntroductionIn preparation for merging the two sets of genomic data, some basic statistics must first be generated. These will include allele frequencies, genotyping rates, missingness, and hardy-weinberg equilibrium tests.
Methods1.Generate allele frequencies for both filesplink1.9 --bfile NI_wgs_merged_snps --freq --out plink_output/wgs_allele_freqplink1.9 --bfile NImerged.impute2.chrAllX-2014-Oct-02 --freq --out plink_output/snp_allele_freqView head of output2.Plot histograms of allele frequency distributions in both files3.Generate missingness statisticsplink1.</description>
    </item>
    
    <item>
      <title>Trying bmerge function</title>
      <link>/posts/trying-bmerge-function/</link>
      <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/trying-bmerge-function/</guid>
      <description>IntroductionSince the genomic data is in two separate files, they need to be merged to create a unified data set that should contain genome-wide SNP coverage for over 600 NI individuals. Eventually, only the data for the individuals that were part of the NIES will be retained, which should include data for about 300 individuals. The merge will be performed on PLINK using the ‘bmerge’ function. To try this, I will be using a small subset of data to familiarise myself with the function and its output.</description>
    </item>
    
    <item>
      <title>Getting started with PLINK</title>
      <link>/posts/getting-started-with-plink/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/getting-started-with-plink/</guid>
      <description>IntroductionAfter cleaning the phenotypic data and performing PCA, the first part of Aim 1 is completed. The second part will involve cleaing and performing PCA on the genomic data. The genomic data is currently in two separate files as they were generated using two different methods (SNP-array and WGS) for different studies. 506 individuals have SNP-array data, and 108 have WGS data, although not all of these individuals were part of the NIES.</description>
    </item>
    
    <item>
      <title>PCA of Phenotypic Data </title>
      <link>/posts/pca-of-phenotypic-data/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/pca-of-phenotypic-data/</guid>
      <description># required packagesrequire(tidyverse)require(broom)require(missMDA)require(FactoMineR)require(moments)require(Hmisc)require(corrplot)IntroductionThe results of the Pearson correlations between the phenotypic variables, indicate that there were several correlated variables, that were not due to being left and right values of the same variable. For example, the keratometry measurements were negatively correlated with axial length. These relationships suggest that there is an underlying component, or a latent phenotype, that may better explain these variables.</description>
    </item>
    
    <item>
      <title>Adding Conjunctival UVAF to dataset </title>
      <link>/posts/adding-conjunctival-uvaf-to-dataset/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/adding-conjunctival-uvaf-to-dataset/</guid>
      <description># required packagesrequire(tidyverse)require(broom)require(missMDA)require(FactoMineR)require(moments)require(Hmisc)require(corrplot)IntroductionUpon inspection of the current data set being used, we realised that there was a variable missing. The variable was a total meausure of conjunctival ultraviolet fluorescence (UVAF). This was included in the original NI Eye Study and therefore, we decided to introduce the variable to this study.
Methods and Results1. Load phenotype dataphen.data.uvaf &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/NIES_master_database_120815_data_dictionary-2.csv&amp;#39;)head(phen.</description>
    </item>
    
    <item>
      <title>Pearson&#39;s correlations on imputed data set</title>
      <link>/posts/pearson-s-correlations-on-imputed-data-set/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/pearson-s-correlations-on-imputed-data-set/</guid>
      <description># required packagesrequire(corrplot)require(missMDA)require(FactoMineR)library(Hmisc)IntroductionPrior to performing principal component analyses, bivariate correlations need to be performed between variables to determine any underlying relationships. This is because PCA indentifies components that may better explain relationships or variability among variables that are related. If none of the variables are correlated, it would be futile to perform a PCA.
Methods and Results1. Load dataphen.data.age &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/NIES_master_database-age.csv&amp;#39;)phen.</description>
    </item>
    
    <item>
      <title>MIPCA of Phenotypic Data without LogMAR-with-PH values</title>
      <link>/posts/mipca-of-phenotypic-data-without-logmar-with-ph-values/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/mipca-of-phenotypic-data-without-logmar-with-ph-values/</guid>
      <description># required packagesrequire(tidyverse)require(broom)require(missMDA)require(FactoMineR)require(moments)require(Hmisc)require(corrplot)IntroductionAfter adding in additional variables, which included logMAR and base-out prism test values, the variable factor plots indicated that there was a large uncertainty around the imputed values of the logMAR with pinhole correction values. Therefore, the right and left pinhole correction variables (LVA and RVA with PH).
Methods and Results1. Subset quantitative variables excluding LVA and RVA with PH variables.</description>
    </item>
    
    <item>
      <title>Multiple PCA Imputation of Quantitative Phenotypic Data  - updated</title>
      <link>/posts/multiple-pca-imputation-of-quantitative-phenotypic-data-updated/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/multiple-pca-imputation-of-quantitative-phenotypic-data-updated/</guid>
      <description>IntroductionMultiple imputation with PCA performed on larger data set.
Methods and Results1. Load dataphen.data.age &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/NIES_master_database-age.csv&amp;#39;)#include logMAR and base-out prism test values phen.data.adults&amp;lt;-phen.data.age[phen.data.age$Age.excel&amp;gt;17,]quant.variables&amp;lt;- c(&amp;quot;Logmar.VA.Right&amp;quot;, &amp;quot;RVA.with.PH&amp;quot;, &amp;quot;Logmar.VA.Left&amp;quot;, &amp;quot;LVA.with.PH&amp;quot;, &amp;quot;R.Sph..pre.dilate.&amp;quot;, &amp;quot;R.Cyl..pre.dilate.&amp;quot;,&amp;quot;R.Axis..pre.dilate.&amp;quot;, &amp;quot;L.Sph..pre.dilate.&amp;quot;, &amp;quot;L.Cyl..pre.dilate.&amp;quot;, &amp;quot;L.Axis..pre.dilate.&amp;quot;,&amp;quot;R.K.value.H&amp;quot;, &amp;quot;R.K.Value.H.Axis&amp;quot;, &amp;quot;R.K.value.V&amp;quot;, &amp;quot;R.K.value.V.Axis&amp;quot;, &amp;quot;L.K.value.H&amp;quot;,&amp;quot;L.K.value.H.Axis&amp;quot;, &amp;quot;L.K.value.V&amp;quot;, &amp;quot;L.K.value.V.Axis&amp;quot;, &amp;quot;R.Pachimetry&amp;quot;, &amp;quot;L.Pachimetry&amp;quot;, &amp;quot;R.Axial.Length&amp;quot;,&amp;quot;L.Axial.Length&amp;quot;, &amp;quot;AC.Depth.R&amp;quot;, &amp;quot;AC.Depth.L&amp;quot;, &amp;quot;R.IOP.mmHg&amp;quot;, &amp;quot;L.IOP.mmHg&amp;quot;, &amp;quot;CDR.RE&amp;quot;, &amp;quot;CDR.LE&amp;quot;)quant.data.adults&amp;lt;- phen.data.adults[quant.variables]summary(quant.data.adults)## Logmar.VA.Right RVA.with.PH Logmar.VA.Left ## Min. :-0.30000 Min. :-0.2400 Min. :-0.</description>
    </item>
    
    <item>
      <title>Multiple PCA Imputation of Phenotypic Data</title>
      <link>/posts/multiple-pca-imputation-of-phenotypic-data/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/multiple-pca-imputation-of-phenotypic-data/</guid>
      <description>IntroductionMultiple imputation using PCA is an effective method for imputing an incomplete data set with missing at random (MAR) data. It takes into account the variability of the data and the uncertainty of the predicted values. By doing so, the resulting imputed data set has integrity and is filled with values that will be valuable in subsequent statistical analyses. This is unlike other standard methods of imputation, like using mean or regression imputation, which is single dimensional and may skew results of further analyses.</description>
    </item>
    
    <item>
      <title>Example of data imputation with missMDA</title>
      <link>/posts/example-of-data-impuation-with-missmda/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/example-of-data-impuation-with-missmda/</guid>
      <description>IntroductionThis entry will show the results of a single imputation using the missMDA package. The missMDA package imputes quantitative variables using principal component analysis (PCA).
Methods and Resultsload dataphen.data.age &amp;lt;- read.csv(&amp;#39;C:/Users/Martha/Documents/Honours/Project/honours.project/Data/NIES_master_database-age.csv&amp;#39;)phen.data.adults&amp;lt;-phen.data.age[phen.data.age$Age.excel&amp;gt;17,]quant.variables&amp;lt;- c(&amp;quot;R.K.value.H&amp;quot;, &amp;quot;R.K.Value.H.Axis&amp;quot;, &amp;quot;R.K.value.V&amp;quot;, &amp;quot;R.K.value.V.Axis&amp;quot;, &amp;quot;L.K.value.H&amp;quot;,&amp;quot;L.K.value.H.Axis&amp;quot;, &amp;quot;L.K.value.V&amp;quot;, &amp;quot;L.K.value.V.Axis&amp;quot;, &amp;quot;R.Pachimetry&amp;quot;, &amp;quot;L.Pachimetry&amp;quot;, &amp;quot;R.Axial.Length&amp;quot;,&amp;quot;L.Axial.Length&amp;quot;, &amp;quot;AC.Depth.R&amp;quot;, &amp;quot;AC.Depth.L&amp;quot;, &amp;quot;R.IOP.mmHg&amp;quot;, &amp;quot;L.IOP.mmHg&amp;quot;, &amp;quot;CDR.RE&amp;quot;, &amp;quot;CDR.LE&amp;quot;)quant.data.adults&amp;lt;- phen.data.adults[quant.variables]install relevant packagesinstall.packages(&amp;#39;missMDA&amp;#39;, dependencies = TRUE, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;)## Installing package into &amp;#39;C:/Users/Martha/Documents/R/win-library/3.</description>
    </item>
    
    <item>
      <title>Understanding PCA </title>
      <link>/posts/understanding-pca/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/understanding-pca/</guid>
      <description>IntroductionPrincipal component analysis (PCA) is one of the analysis techniques that I will be performing on my data. For the phenotypic dataset, it will be used to impute missing values to obtain a complete dataset. Later on, PCA will be performed to determine principal components of the endophenotypes to identify any latent phenotypes.
http://setosa.io/ev/principal-component-analysis/
https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/
</description>
    </item>
    
    <item>
      <title>Subsetting relevant phenotypic data</title>
      <link>/posts/subsetting-relevant-phenotypic-data/</link>
      <pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/subsetting-relevant-phenotypic-data/</guid>
      <description>IntroductionThe original dataset that was used for descriptive statistics in previous entries contained data for all 801 individuals. However, the ethics approval for this study only allows for adult data to be included in the study. All data for minor individuals must therefore be removed. Additionally, relevant quantitative variables must be selected from the bigger phenotypic dataset since not all quantitative measurements are endophenotypes.
AimRemove data for minor individuals and subset relevant quantitative measures.</description>
    </item>
    
    <item>
      <title>Understanding ocular biometric measurements</title>
      <link>/posts/understanding-oculab-biometric-measurements/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/understanding-oculab-biometric-measurements/</guid>
      <description>IntroductionThe histograms and outliers have not revealed any non-sense data - in a statistical sense. However, the data that was collected from the eye examinations as part of the NIES in 2008 was not accompanied with a comprehensive glossary. In order to understand the measurements, and determine whether some values are outside of the possible measurable outcomes, compiling a glossary would be useful.
Keratometry - measure of corneal radius of curvature</description>
    </item>
    
    <item>
      <title>Finding outliers in quantitative data</title>
      <link>/posts/finding-outliers-in-quantitative-data/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/finding-outliers-in-quantitative-data/</guid>
      <description>IntroductionFinding outliers in a dataset help identify any non-sense data that may not be obvious from the histograms. If they are not non-sense, they may be present due to measurement variability or it may indicate an error. Regardless, it is important to identify outliers as they can significantly affect the results of subsequent statistical analyses and it may be necessary to exclude them from the dataset prior to data imputation.</description>
    </item>
    
    <item>
      <title>Plotting histograms for quantitative phenotypic data</title>
      <link>/posts/plotting-histograms-for-quantitative-phenotypic-data/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/plotting-histograms-for-quantitative-phenotypic-data/</guid>
      <description>IntroductionHistograms show the frequency distribution of continuous data. It can also be used to inspect whether the data is normally distributed, skewed, and indicate the presence of outliers or non-sense data. The continuous data is split into intervals called bins, and the frequency of scores that fit within each bin is recorded and plotted. Since the data is continuous, histograms are plotted with no spaces in between each bar. (https://statistics.</description>
    </item>
    
    <item>
      <title>Cleaning phenotypic data</title>
      <link>/posts/cleaning-phenotypic-data/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      <author>eunise.aquino@connect.qut.edu.au (Martha Aquino)</author>
      <guid>/posts/cleaning-phenotypic-data/</guid>
      <description>IntroductionThe phenotypic data collected from the eye examinations in 2008 were collated in a single excel file. The file contains data from all 801 study participants, including their demographic, environmental, and quantitative phenotypic data. There are also comments on clinical observations. Prior to analysing the phenotypic data, it is important to identify any missing or non-sense data so as not to interfere with the analyses or its results.
AimTo identify missing and non-sense data from the phenotypic dataset.</description>
    </item>
    
  </channel>
</rss>